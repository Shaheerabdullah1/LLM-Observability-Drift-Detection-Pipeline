{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage-1 Data Collection and Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T15:32:24.466010Z",
     "iopub.status.busy": "2026-02-04T15:32:24.465594Z",
     "iopub.status.idle": "2026-02-04T15:32:24.471139Z",
     "shell.execute_reply": "2026-02-04T15:32:24.469683Z",
     "shell.execute_reply.started": "2026-02-04T15:32:24.465974Z"
    }
   },
   "source": [
    "## STEP 1 - Load SQuAD v1 JSON properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-04T15:28:52.414315Z",
     "iopub.status.busy": "2026-02-04T15:28:52.414046Z",
     "iopub.status.idle": "2026-02-04T15:28:53.122575Z",
     "shell.execute_reply": "2026-02-04T15:28:53.121661Z",
     "shell.execute_reply.started": "2026-02-04T15:28:52.414289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "SQUAD_PATH = \"/kaggle/input/stanford-question-answering-dataset/train-v1.1.json\"\n",
    "\n",
    "with open(SQUAD_PATH, \"r\") as f:\n",
    "    squad_data = json.load(f)\n",
    "\n",
    "len(squad_data[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 - Extract ALL questions (raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T15:32:09.569278Z",
     "iopub.status.busy": "2026-02-04T15:32:09.568889Z",
     "iopub.status.idle": "2026-02-04T15:32:09.611983Z",
     "shell.execute_reply": "2026-02-04T15:32:09.610908Z",
     "shell.execute_reply.started": "2026-02-04T15:32:09.569243Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87599"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = []\n",
    "\n",
    "for article in squad_data[\"data\"]:\n",
    "    for paragraph in article[\"paragraphs\"]:\n",
    "        for qa in paragraph[\"qas\"]:\n",
    "            q = qa[\"question\"].strip()\n",
    "            questions.append(q)\n",
    "\n",
    "len(questions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3 - Clean the questions (VERY IMPORTANT)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T15:32:09.614363Z",
     "iopub.status.busy": "2026-02-04T15:32:09.614002Z",
     "iopub.status.idle": "2026-02-04T15:32:09.887581Z",
     "shell.execute_reply": "2026-02-04T15:32:09.886780Z",
     "shell.execute_reply.started": "2026-02-04T15:32:09.614328Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85549"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def is_good_question(q):\n",
    "    # Length filter\n",
    "    if len(q.split()) < 4 or len(q.split()) > 25:\n",
    "        return False\n",
    "\n",
    "    # Remove context-dependent questions\n",
    "    bad_patterns = [\n",
    "        \"according to\",\n",
    "        \"in the passage\",\n",
    "        \"in the text\",\n",
    "        \"mentioned above\",\n",
    "        \"the paragraph\"\n",
    "    ]\n",
    "\n",
    "    q_lower = q.lower()\n",
    "    if any(p in q_lower for p in bad_patterns):\n",
    "        return False\n",
    "\n",
    "    # Must end with question mark\n",
    "    if not q.endswith(\"?\"):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "clean_questions = [q for q in questions if is_good_question(q)]\n",
    "\n",
    "len(clean_questions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4 - Deduplicate (don’t skip this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T15:32:09.889274Z",
     "iopub.status.busy": "2026-02-04T15:32:09.889013Z",
     "iopub.status.idle": "2026-02-04T15:32:09.923214Z",
     "shell.execute_reply": "2026-02-04T15:32:09.922106Z",
     "shell.execute_reply.started": "2026-02-04T15:32:09.889251Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85309"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_questions = list(set(clean_questions))\n",
    "len(clean_questions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5 - Categorize questions (lightweight, rule-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T15:32:09.924953Z",
     "iopub.status.busy": "2026-02-04T15:32:09.924578Z",
     "iopub.status.idle": "2026-02-04T15:32:10.008352Z",
     "shell.execute_reply": "2026-02-04T15:32:10.007385Z",
     "shell.execute_reply.started": "2026-02-04T15:32:09.924913Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factual 53654\n",
      "explanatory 9179\n",
      "ambiguous 22476\n"
     ]
    }
   ],
   "source": [
    "def categorize(q):\n",
    "    q_lower = q.lower()\n",
    "    if q_lower.startswith((\"who\", \"what\", \"when\", \"where\")):\n",
    "        return \"factual\"\n",
    "    if q_lower.startswith((\"why\", \"how\")):\n",
    "        return \"explanatory\"\n",
    "    return \"ambiguous\"\n",
    "\n",
    "categorized = {\n",
    "    \"factual\": [],\n",
    "    \"explanatory\": [],\n",
    "    \"ambiguous\": []\n",
    "}\n",
    "\n",
    "for q in clean_questions:\n",
    "    categorized[categorize(q)].append(q)\n",
    "\n",
    "for k, v in categorized.items():\n",
    "    print(k, len(v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6 - Sample EXACTLY 150 questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T16:40:20.535345Z",
     "iopub.status.busy": "2026-02-04T16:40:20.534938Z",
     "iopub.status.idle": "2026-02-04T16:40:20.543377Z",
     "shell.execute_reply": "2026-02-04T16:40:20.542159Z",
     "shell.execute_reply.started": "2026-02-04T16:40:20.535309Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "squad_selected = (\n",
    "    random.sample(categorized[\"factual\"], 60) +\n",
    "    random.sample(categorized[\"explanatory\"], 60) +\n",
    "    random.sample(categorized[\"ambiguous\"], 30)\n",
    ")\n",
    "\n",
    "len(squad_selected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 7 - Save SQuAD prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T16:41:34.673570Z",
     "iopub.status.busy": "2026-02-04T16:41:34.673182Z",
     "iopub.status.idle": "2026-02-04T16:41:34.686057Z",
     "shell.execute_reply": "2026-02-04T16:41:34.685075Z",
     "shell.execute_reply.started": "2026-02-04T16:41:34.673541Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "factual        60\n",
       "explanatory    60\n",
       "ambiguous      30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "squad_df = pd.DataFrame({\n",
    "    \"prompt_id\": [f\"SQUAD_{i+1:03d}\" for i in range(len(squad_selected))],\n",
    "    \"source\": \"squad_v1\",\n",
    "    \"prompt_text\": squad_selected,\n",
    "    \"category\": [categorize(q) for q in squad_selected]\n",
    "})\n",
    "\n",
    "# Save updated SQuAD prompts\n",
    "squad_df.to_csv(\"/kaggle/working/squad_prompts_150.csv\", index=False)\n",
    "\n",
    "# Verify category distribution\n",
    "squad_df[\"category\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T16:41:45.588922Z",
     "iopub.status.busy": "2026-02-04T16:41:45.588418Z",
     "iopub.status.idle": "2026-02-04T16:41:45.600732Z",
     "shell.execute_reply": "2026-02-04T16:41:45.599074Z",
     "shell.execute_reply.started": "2026-02-04T16:41:45.588886Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>source</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SQUAD_001</td>\n",
       "      <td>squad_v1</td>\n",
       "      <td>What is the oldest Presbyterian church in Rich...</td>\n",
       "      <td>factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SQUAD_002</td>\n",
       "      <td>squad_v1</td>\n",
       "      <td>Who is the CCO of Sony Music?</td>\n",
       "      <td>factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SQUAD_003</td>\n",
       "      <td>squad_v1</td>\n",
       "      <td>When were late Paleolithic communities establi...</td>\n",
       "      <td>factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SQUAD_004</td>\n",
       "      <td>squad_v1</td>\n",
       "      <td>Who eventually defeated the Arabs at Rajasthan?</td>\n",
       "      <td>factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SQUAD_005</td>\n",
       "      <td>squad_v1</td>\n",
       "      <td>What part of a polychaete can be everted?</td>\n",
       "      <td>factual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_id    source                                        prompt_text  \\\n",
       "0  SQUAD_001  squad_v1  What is the oldest Presbyterian church in Rich...   \n",
       "1  SQUAD_002  squad_v1                      Who is the CCO of Sony Music?   \n",
       "2  SQUAD_003  squad_v1  When were late Paleolithic communities establi...   \n",
       "3  SQUAD_004  squad_v1    Who eventually defeated the Arabs at Rajasthan?   \n",
       "4  SQUAD_005  squad_v1          What part of a polychaete can be everted?   \n",
       "\n",
       "  category  \n",
       "0  factual  \n",
       "1  factual  \n",
       "2  factual  \n",
       "3  factual  \n",
       "4  factual  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T16:42:01.386380Z",
     "iopub.status.busy": "2026-02-04T16:42:01.386003Z",
     "iopub.status.idle": "2026-02-04T16:42:01.392432Z",
     "shell.execute_reply": "2026-02-04T16:42:01.391727Z",
     "shell.execute_reply.started": "2026-02-04T16:42:01.386350Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(squad_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Questions Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1 - Load Natural Questions CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T16:28:06.480967Z",
     "iopub.status.busy": "2026-02-04T16:28:06.480276Z",
     "iopub.status.idle": "2026-02-04T16:28:07.691445Z",
     "shell.execute_reply": "2026-02-04T16:28:07.690332Z",
     "shell.execute_reply.started": "2026-02-04T16:28:06.480925Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>long_answers</th>\n",
       "      <th>short_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which is the most common use of opt-in e-mail ...</td>\n",
       "      <td>A common example of permission marketing is a ...</td>\n",
       "      <td>A newsletter sent to an advertising firm's cus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how i.met your mother who is the mother</td>\n",
       "      <td>Tracy McConnell, better known as `` The Mother...</td>\n",
       "      <td>Tracy McConnell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>who had the most wins in the nfl</td>\n",
       "      <td>Active quarterback Tom Brady holds the records...</td>\n",
       "      <td>Tom Brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who played mantis guardians of the galaxy 2</td>\n",
       "      <td>Pom Klementieff (born May 1986) is a French ac...</td>\n",
       "      <td>Pom Klementieff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the nashville sound brought a polished and cos...</td>\n",
       "      <td>In the early 1960s, the Nashville sound began ...</td>\n",
       "      <td>The use of lush string arrangements with a rea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  which is the most common use of opt-in e-mail ...   \n",
       "1            how i.met your mother who is the mother   \n",
       "2                   who had the most wins in the nfl   \n",
       "3        who played mantis guardians of the galaxy 2   \n",
       "4  the nashville sound brought a polished and cos...   \n",
       "\n",
       "                                        long_answers  \\\n",
       "0  A common example of permission marketing is a ...   \n",
       "1  Tracy McConnell, better known as `` The Mother...   \n",
       "2  Active quarterback Tom Brady holds the records...   \n",
       "3  Pom Klementieff (born May 1986) is a French ac...   \n",
       "4  In the early 1960s, the Nashville sound began ...   \n",
       "\n",
       "                                       short_answers  \n",
       "0  A newsletter sent to an advertising firm's cus...  \n",
       "1                                    Tracy McConnell  \n",
       "2                                          Tom Brady  \n",
       "3                                    Pom Klementieff  \n",
       "4  The use of lush string arrangements with a rea...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "NQ_PATH = \"/kaggle/input/natural-questions-dataset/Natural-Questions-Filtered.csv\"\n",
    "\n",
    "nq_df = pd.read_csv(NQ_PATH)\n",
    "nq_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T16:28:26.862154Z",
     "iopub.status.busy": "2026-02-04T16:28:26.861781Z",
     "iopub.status.idle": "2026-02-04T16:28:26.868937Z",
     "shell.execute_reply": "2026-02-04T16:28:26.868001Z",
     "shell.execute_reply.started": "2026-02-04T16:28:26.862120Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question', 'long_answers', 'short_answers'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nq_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1.1 - Extract questions safely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T16:29:37.207528Z",
     "iopub.status.busy": "2026-02-04T16:29:37.207134Z",
     "iopub.status.idle": "2026-02-04T16:29:37.251598Z",
     "shell.execute_reply": "2026-02-04T16:29:37.250639Z",
     "shell.execute_reply.started": "2026-02-04T16:29:37.207500Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86212"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = (\n",
    "    nq_df[\"question\"]\n",
    "    .dropna()\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "len(questions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 — Apply STRICT filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T16:30:00.316632Z",
     "iopub.status.busy": "2026-02-04T16:30:00.316258Z",
     "iopub.status.idle": "2026-02-04T16:30:00.560598Z",
     "shell.execute_reply": "2026-02-04T16:30:00.559149Z",
     "shell.execute_reply.started": "2026-02-04T16:30:00.316601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74527"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_good_nq_question(q):\n",
    "    # length filter: search-style queries\n",
    "    if len(q.split()) < 3 or len(q.split()) > 15:\n",
    "        return False\n",
    "\n",
    "    q_lower = q.lower()\n",
    "\n",
    "    # remove noise / artifacts\n",
    "    if any(x in q_lower for x in [\"http\", \"<\", \">\", \"{\", \"}\", \"[\", \"]\"]):\n",
    "        return False\n",
    "\n",
    "    # must look like a real question\n",
    "    if not (\n",
    "        q_lower.startswith((\"who\", \"what\", \"when\", \"where\", \"why\", \"how\"))\n",
    "        or q.endswith(\"?\")\n",
    "    ):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "clean_nq = [q for q in questions if is_good_nq_question(q)]\n",
    "clean_nq = list(set(clean_nq))  # deduplicate\n",
    "\n",
    "len(clean_nq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3 - Categorize (same logic as SQuAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T16:34:17.850838Z",
     "iopub.status.busy": "2026-02-04T16:34:17.850290Z",
     "iopub.status.idle": "2026-02-04T16:34:17.917778Z",
     "shell.execute_reply": "2026-02-04T16:34:17.916285Z",
     "shell.execute_reply.started": "2026-02-04T16:34:17.850801Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factual 70073\n",
      "explanatory 4454\n"
     ]
    }
   ],
   "source": [
    "def categorize_nq(q):\n",
    "    q_lower = q.lower()\n",
    "    if q_lower.startswith((\"why\", \"how\")):\n",
    "        return \"explanatory\"\n",
    "    return \"factual\"  # everything else\n",
    "categorized_nq = {\n",
    "    \"factual\": [],\n",
    "    \"explanatory\": []\n",
    "}\n",
    "\n",
    "for q in clean_nq:\n",
    "    categorized_nq[categorize_nq(q)].append(q)\n",
    "\n",
    "for k, v in categorized_nq.items():\n",
    "    print(k, len(v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Sample EXACTLY 150 (final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T16:34:39.050612Z",
     "iopub.status.busy": "2026-02-04T16:34:39.050205Z",
     "iopub.status.idle": "2026-02-04T16:34:39.060550Z",
     "shell.execute_reply": "2026-02-04T16:34:39.059243Z",
     "shell.execute_reply.started": "2026-02-04T16:34:39.050579Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "nq_selected = (\n",
    "    random.sample(categorized_nq[\"factual\"], 100)\n",
    "    + random.sample(categorized_nq[\"explanatory\"], 50)\n",
    ")\n",
    "\n",
    "len(nq_selected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Save & FREEZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T16:35:07.275098Z",
     "iopub.status.busy": "2026-02-04T16:35:07.274673Z",
     "iopub.status.idle": "2026-02-04T16:35:07.292829Z",
     "shell.execute_reply": "2026-02-04T16:35:07.291834Z",
     "shell.execute_reply.started": "2026-02-04T16:35:07.275064Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>source</th>\n",
       "      <th>category</th>\n",
       "      <th>prompt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NQ_001</td>\n",
       "      <td>natural_questions</td>\n",
       "      <td>factual</td>\n",
       "      <td>when did the nebraska state fair move to grand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NQ_002</td>\n",
       "      <td>natural_questions</td>\n",
       "      <td>factual</td>\n",
       "      <td>who holds the power in an absolute monarchy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NQ_003</td>\n",
       "      <td>natural_questions</td>\n",
       "      <td>factual</td>\n",
       "      <td>who plays the guy in call me maybe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NQ_004</td>\n",
       "      <td>natural_questions</td>\n",
       "      <td>factual</td>\n",
       "      <td>where does season of migration to the north ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NQ_005</td>\n",
       "      <td>natural_questions</td>\n",
       "      <td>factual</td>\n",
       "      <td>when did blue m and ms come out</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id             source category  \\\n",
       "0    NQ_001  natural_questions  factual   \n",
       "1    NQ_002  natural_questions  factual   \n",
       "2    NQ_003  natural_questions  factual   \n",
       "3    NQ_004  natural_questions  factual   \n",
       "4    NQ_005  natural_questions  factual   \n",
       "\n",
       "                                         prompt_text  \n",
       "0  when did the nebraska state fair move to grand...  \n",
       "1        who holds the power in an absolute monarchy  \n",
       "2                 who plays the guy in call me maybe  \n",
       "3  where does season of migration to the north ta...  \n",
       "4                    when did blue m and ms come out  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nq_final = pd.DataFrame({\n",
    "    \"prompt_id\": [f\"NQ_{i+1:03d}\" for i in range(len(nq_selected))],\n",
    "    \"source\": \"natural_questions\",\n",
    "    \"category\": (\n",
    "        [\"factual\"] * 100\n",
    "        + [\"explanatory\"] * 50\n",
    "    ),\n",
    "    \"prompt_text\": nq_selected\n",
    "})\n",
    "\n",
    "nq_final.to_csv(\"/kaggle/working/nq_prompts_150.csv\", index=False)\n",
    "\n",
    "nq_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T16:42:10.360389Z",
     "iopub.status.busy": "2026-02-04T16:42:10.358893Z",
     "iopub.status.idle": "2026-02-04T16:42:10.367824Z",
     "shell.execute_reply": "2026-02-04T16:42:10.366769Z",
     "shell.execute_reply.started": "2026-02-04T16:42:10.360299Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nq_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge both datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Load both CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T16:44:31.428051Z",
     "iopub.status.busy": "2026-02-04T16:44:31.427388Z",
     "iopub.status.idle": "2026-02-04T16:44:31.442652Z",
     "shell.execute_reply": "2026-02-04T16:44:31.441459Z",
     "shell.execute_reply.started": "2026-02-04T16:44:31.428005Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQuAD shape: (150, 4)\n",
      "NQ shape: (150, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "squad_path = \"/kaggle/working/squad_prompts_150.csv\"\n",
    "nq_path = \"/kaggle/working/nq_prompts_150.csv\"\n",
    "\n",
    "squad_df = pd.read_csv(squad_path)\n",
    "nq_df = pd.read_csv(nq_path)\n",
    "\n",
    "print(\"SQuAD shape:\", squad_df.shape)\n",
    "print(\"NQ shape:\", nq_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 - Schema check + alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T16:46:31.993839Z",
     "iopub.status.busy": "2026-02-04T16:46:31.992762Z",
     "iopub.status.idle": "2026-02-04T16:46:32.045706Z",
     "shell.execute_reply": "2026-02-04T16:46:32.044753Z",
     "shell.execute_reply.started": "2026-02-04T16:46:31.993794Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['prompt_id', 'source', 'category', 'prompt_text'], dtype='object'),\n",
       " Index(['prompt_id', 'source', 'category', 'prompt_text'], dtype='object'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define canonical column order\n",
    "CANONICAL_COLUMNS = [\"prompt_id\", \"source\", \"category\", \"prompt_text\"]\n",
    "\n",
    "# Check column sets (order-independent)\n",
    "assert set(squad_df.columns) == set(nq_df.columns), \"Column sets do not match!\"\n",
    "\n",
    "# Reorder columns consistently\n",
    "squad_df = squad_df[CANONICAL_COLUMNS]\n",
    "nq_df = nq_df[CANONICAL_COLUMNS]\n",
    "\n",
    "squad_df.columns, nq_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Merge (concatenate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T16:47:30.170093Z",
     "iopub.status.busy": "2026-02-04T16:47:30.169523Z",
     "iopub.status.idle": "2026-02-04T16:47:30.178649Z",
     "shell.execute_reply": "2026-02-04T16:47:30.177490Z",
     "shell.execute_reply.started": "2026-02-04T16:47:30.170055Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_df = pd.concat([squad_df, nq_df], ignore_index=True)\n",
    "\n",
    "prompts_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Final integrity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T16:47:48.671756Z",
     "iopub.status.busy": "2026-02-04T16:47:48.671302Z",
     "iopub.status.idle": "2026-02-04T16:47:48.680707Z",
     "shell.execute_reply": "2026-02-04T16:47:48.679680Z",
     "shell.execute_reply.started": "2026-02-04T16:47:48.671722Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "squad_v1             150\n",
       "natural_questions    150\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check counts by source\n",
    "prompts_df[\"source\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T16:48:11.970949Z",
     "iopub.status.busy": "2026-02-04T16:48:11.969935Z",
     "iopub.status.idle": "2026-02-04T16:48:11.978335Z",
     "shell.execute_reply": "2026-02-04T16:48:11.977305Z",
     "shell.execute_reply.started": "2026-02-04T16:48:11.970906Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "factual        160\n",
       "explanatory    110\n",
       "ambiguous       30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check category distribution\n",
    "prompts_df[\"category\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Save final merged dataset (FREEZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T16:48:36.164079Z",
     "iopub.status.busy": "2026-02-04T16:48:36.162887Z",
     "iopub.status.idle": "2026-02-04T16:48:36.178039Z",
     "shell.execute_reply": "2026-02-04T16:48:36.176910Z",
     "shell.execute_reply.started": "2026-02-04T16:48:36.164033Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>source</th>\n",
       "      <th>category</th>\n",
       "      <th>prompt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SQUAD_001</td>\n",
       "      <td>squad_v1</td>\n",
       "      <td>factual</td>\n",
       "      <td>What is the oldest Presbyterian church in Rich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SQUAD_002</td>\n",
       "      <td>squad_v1</td>\n",
       "      <td>factual</td>\n",
       "      <td>Who is the CCO of Sony Music?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SQUAD_003</td>\n",
       "      <td>squad_v1</td>\n",
       "      <td>factual</td>\n",
       "      <td>When were late Paleolithic communities establi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SQUAD_004</td>\n",
       "      <td>squad_v1</td>\n",
       "      <td>factual</td>\n",
       "      <td>Who eventually defeated the Arabs at Rajasthan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SQUAD_005</td>\n",
       "      <td>squad_v1</td>\n",
       "      <td>factual</td>\n",
       "      <td>What part of a polychaete can be everted?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_id    source category  \\\n",
       "0  SQUAD_001  squad_v1  factual   \n",
       "1  SQUAD_002  squad_v1  factual   \n",
       "2  SQUAD_003  squad_v1  factual   \n",
       "3  SQUAD_004  squad_v1  factual   \n",
       "4  SQUAD_005  squad_v1  factual   \n",
       "\n",
       "                                         prompt_text  \n",
       "0  What is the oldest Presbyterian church in Rich...  \n",
       "1                      Who is the CCO of Sony Music?  \n",
       "2  When were late Paleolithic communities establi...  \n",
       "3    Who eventually defeated the Arabs at Rajasthan?  \n",
       "4          What part of a polychaete can be everted?  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_df.to_csv(\"/kaggle/working/prompts.csv\", index=False)\n",
    "\n",
    "prompts_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 374,
     "sourceId": 799923,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4605254,
     "sourceId": 7852433,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
